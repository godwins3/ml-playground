{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/godwins3/ml-playground/blob/main/projects/nsfw_media.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner\n",
        "# !pip install scikit-learn\n"
      ],
      "metadata": {
        "id": "gg2ZkuSRAVN-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ad9a35b-fe8d-4eca-a931-436da7f2d61c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (13.9.3)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.13.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_pusl9BgARnK"
      },
      "outputs": [],
      "source": [
        "import keras_tuner as kt\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import sklearn.metrics\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import glob\n",
        "\n",
        "from tqdm import tqdm\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from google.cloud import storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btOD0KyYARnO",
        "outputId": "b0b623ae-febb-4f12-f1c3-671730d9800b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "physical_devices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bHPklyYARnP",
        "outputId": "3a7be6a8-14f7-446d-f2de-5b0ba4a347f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "tf.config.set_visible_devices([tf.config.PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')], 'GPU')\n",
        "tf.config.get_visible_devices('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Uu7qdjiOARnP"
      },
      "outputs": [],
      "source": [
        "def decode_fn_embedding(example_proto):\n",
        "    feature_description = {\n",
        "        'embedding': tf.io.FixedLenFeature([256], dtype = tf.float32),\n",
        "        'labels': tf.io.FixedLenFeature([], dtype = tf.int64)\n",
        "    }\n",
        "    example = tf.io.parse_single_example(\n",
        "        example_proto,\n",
        "        feature_description\n",
        "    )\n",
        "\n",
        "    return example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tUu1zx00ARnP"
      },
      "outputs": [],
      "source": [
        "def preprocess_embedding_example(example_dict, positive_label = 1, features_as_dict = False):\n",
        "    labels = example_dict['labels']\n",
        "    label = tf.math.reduce_any(labels == positive_label)\n",
        "    label = tf.cast(label, tf.int32)\n",
        "    embedding = example_dict['embedding']\n",
        "    if features_as_dict:\n",
        "        features = {'embedding': embedding}\n",
        "    else:\n",
        "        features = embedding\n",
        "\n",
        "    return features, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fpLlKoE7ARnQ"
      },
      "outputs": [],
      "source": [
        "input_root = ...\n",
        "sens_prev_input_root = ...\n",
        "\n",
        "use_sens_prev_data = True\n",
        "has_validation_data = True\n",
        "positive_label = 1\n",
        "\n",
        "train_batch_size = 256\n",
        "test_batch_size = 256\n",
        "validation_batch_size = 256\n",
        "\n",
        "do_resample = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "l84VmyWFARnQ"
      },
      "outputs": [],
      "source": [
        "def class_func(features, labels):\n",
        "    return labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5T87IenUARnQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb0a511a-d6e3-4875-82ea-fffbf2fdc081"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-9-895bf95c244c>:1: rejection_resample (from tensorflow.python.data.experimental.ops.resampling) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.rejection_resample(...)`.\n"
          ]
        }
      ],
      "source": [
        "resample_fn = tf.data.experimental.rejection_resample(\n",
        "    class_func, target_dist = [0.5, 0.5], seed = 0\n",
        ")\n",
        "train_glob = f\"{input_root}/train/tfrecord/*.tfrecord\"\n",
        "train_files = tf.io.gfile.glob(train_glob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "I0LAeEdjARnR"
      },
      "outputs": [],
      "source": [
        "if use_sens_prev_data:\n",
        "    train_sens_prev_glob = f\"{sens_prev_input_root}/train/tfrecord/*.tfrecord\"\n",
        "    train_sens_prev_files = tf.io.gfile.glob(train_sens_prev_glob)\n",
        "    train_files = train_files + train_sens_prev_files\n",
        "random.shuffle(train_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "rnq-vXWHARnR",
        "outputId": "df254cf4-7876-4686-f735-ecf9e4ec7f11"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Did not find any train files matching Ellipsis/train/tfrecord/*.tfrecord",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-b1aa9f59102f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Did not find any train files matching {train_glob}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: Did not find any train files matching Ellipsis/train/tfrecord/*.tfrecord"
          ]
        }
      ],
      "source": [
        "if not len(train_files):\n",
        "    raise ValueError(f\"Did not find any train files matching {train_glob}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5qf_XKxaARnR"
      },
      "outputs": [],
      "source": [
        "test_glob = f\"{input_root}/test/tfrecord/*.tfrecord\"\n",
        "test_files =  tf.io.gfile.glob(test_glob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "K1YvecEsARnS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "5f9844a8-6064-4713-9aeb-1d3f64097522"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Did not find any eval files matching Ellipsis/test/tfrecord/*.tfrecord",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-f5a06590ecb1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Did not find any eval files matching {test_glob}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: Did not find any eval files matching Ellipsis/test/tfrecord/*.tfrecord"
          ]
        }
      ],
      "source": [
        "if not len(test_files):\n",
        "    raise ValueError(f\"Did not find any eval files matching {test_glob}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RMLejicZARnS"
      },
      "outputs": [],
      "source": [
        "test_ds = tf.data.TFRecordDataset(test_files).map(decode_fn_embedding)\n",
        "test_ds = test_ds.map(lambda x: preprocess_embedding_example(x, positive_label=positive_label)).batch(batch_size=test_batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "I67HL6mjARnS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "b2ca47b5-0d35-4f4b-fea4-d897f10c71ea"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-15-42b8568d238b>, line 9)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-42b8568d238b>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    test_sens_prev_ds = test_sens_prev_ds.map(lambda x: preprocess_embedding_example(x, positive_label=positive_label)).batch(batch_size=test_batch_size)test_sens_prev_ds = test_sens_prev_ds.map(lambda x: preprocess_embedding_example(x, positive_label=positive_label)).batch(batch_size=test_batch_size)\u001b[0m\n\u001b[0m                                                                                                                                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "if use_sens_prev_data:\n",
        "    test_sens_prev_glob = f\"{sens_prev_input_root}/test/tfrecord/*.tfrecord\"\n",
        "    test_sens_prev_files =  tf.io.gfile.glob(test_sens_prev_glob)\n",
        "\n",
        "    if not len(test_sens_prev_files):\n",
        "        raise ValueError(f\"Did not find any eval files matching {test_sens_prev_glob}\")\n",
        "\n",
        "    test_sens_prev_ds = tf.data.TFRecordDataset(test_sens_prev_files).map(decode_fn_embedding)\n",
        "    test_sens_prev_ds = test_sens_prev_ds.map(lambda x: preprocess_embedding_example(x, positive_label=positive_label)).batch(batch_size=test_batch_size)test_sens_prev_ds = test_sens_prev_ds.map(lambda x: preprocess_embedding_example(x, positive_label=positive_label)).batch(batch_size=test_batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASIy6G6HARnS"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.data.TFRecordDataset(train_files).map(decode_fn_embedding)\n",
        "train_ds = train_ds.map(lambda x: preprocess_embedding_example(x, positive_label=positive_label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhY7YbOlARnT"
      },
      "outputs": [],
      "source": [
        "if do_resample:\n",
        "    train_ds = train_ds.apply(resample_fn).map(lambda _,b:(b))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLlPWbInARnT"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.batch(batch_size=256).shuffle(buffer_size=10)\n",
        "train_ds = train_ds.repeat()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gEvuFlOARnT"
      },
      "outputs": [],
      "source": [
        "if has_validation_data:\n",
        "    eval_glob = f\"{input_root}/validation/tfrecord/*.tfrecord\"\n",
        "    eval_files =  tf.io.gfile.glob(eval_glob)\n",
        "\n",
        "    if use_sens_prev_data:\n",
        "        eval_sens_prev_glob = f\"{sens_prev_input_root}/validation/tfrecord/*.tfrecord\"\n",
        "        eval_sens_prev_files = tf.io.gfile.glob(eval_sens_prev_glob)\n",
        "        eval_files =  eval_files + eval_sens_prev_files\n",
        "\n",
        "    if not len(eval_files):\n",
        "        raise ValueError(f\"Did not find any eval files matching {eval_glob}\")\n",
        "\n",
        "    eval_ds = tf.data.TFRecordDataset(eval_files).map(decode_fn_embedding)\n",
        "    eval_ds = eval_ds.map(lambda x: preprocess_embedding_example(x, positive_label=positive_label)).batch(batch_size=validation_batch_size)\n",
        "\n",
        "else:\n",
        "    eval_ds = tf.data.TFRecordDataset(test_files).map(decode_fn_embedding)\n",
        "    eval_ds = eval_ds.map(lambda x: preprocess_embedding_example(x, positive_label=positive_label)).batch(batch_size=validation_batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYeXuxcCARnT"
      },
      "outputs": [],
      "source": [
        "check_ds = tf.data.TFRecordDataset(train_files).map(decode_fn_embedding)\n",
        "cnt = 0\n",
        "pos_cnt = 0\n",
        "\n",
        "for example in tqdm(check_ds):\n",
        "    label = example['labels']\n",
        "    if label == 1:\n",
        "        pos_cnt += 1\n",
        "    cnt += 1\n",
        "print(f'{cnt} train entries with {pos_cnt} positive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uhdhsj9vARnT"
      },
      "outputs": [],
      "source": [
        "metrics = []\n",
        "\n",
        "metrics.append(\n",
        "    tf.keras.metrics.PrecisionAtRecall(\n",
        "        recall=0.9, num_thresholds=200, class_id=None, name=None, dtype=None\n",
        "    )\n",
        ")\n",
        "\n",
        "metrics.append(\n",
        "    tf.keras.metrics.AUC(\n",
        "        num_thresholds=200,\n",
        "        curve=\"PR\",\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iMup1gmARnT"
      },
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(\n",
        "        learning_rate = 0.001,\n",
        "        beta_1 = 0.9,\n",
        "        beta_2 = 0.999,\n",
        "        epsilon = 1e-0.8,\n",
        "        amsgrad = False,\n",
        "        name = 'Adam'\n",
        "    )\n",
        "\n",
        "    activation=hp.Choice(\"activation\", [\"tanh\", \"gelu\"])\n",
        "    kernel_initializer=hp.Choice(\"kernel_initializer\", [\"he_uniform\", \"glorot_uniform\"])\n",
        "\n",
        "    for i in range(hp.Int(\"num_layers\", 1, 2)):\n",
        "        model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "        units=hp.Int(\"units\", min_value=128, max_value=256, step=128)\n",
        "\n",
        "        if i == 0:\n",
        "            model.add(\n",
        "                Dense(\n",
        "                    units = units,\n",
        "                    activation=activation,\n",
        "                    kernel_initializer=kernel_initializer,\n",
        "                    input_shape=(None, 256)\n",
        "                )\n",
        "            )\n",
        "        else:\n",
        "            model.add(\n",
        "                units = units,\n",
        "                activation = activation,\n",
        "                kernel_initializer = kernel_initializer,\n",
        "            )\n",
        "    model.add(Dense(1, activation='sigmoid', kernel_initializer = kernel_initializer))\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=metrics)\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yv5aQbU0ARnU"
      },
      "outputs": [],
      "source": [
        "tuner = kt.tuners.BayesianOptimization(\n",
        "    build_model,\n",
        "    objective=kt.Objective('val_loss', direction=\"min\"),\n",
        "    max_trials=30,\n",
        "    directory='tuner_dir',\n",
        "    project_name='with_twitter_clip'\n",
        ")\n",
        "\n",
        "callbacks = [tf.keras.callbacks.EarlyStopping(\n",
        "    monitor = 'val_loss', min_delta = 0, patience = 5, verbose = 0,\n",
        "    mode = 'auto', baseline = None, restore_best_weights = True\n",
        ")]\n",
        "\n",
        "steps_per_epoch = 400\n",
        "tuner.search(\n",
        "    train_ds,\n",
        "    epochs = 100,\n",
        "    batch_size = 256,\n",
        "    steps_per_epoch = steps_per_epoch,\n",
        "    verbose = 2,\n",
        "    validation_data=eval_ds,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "tuner.results_summary()\n",
        "models = tuner.get_best_models(num_models=2)\n",
        "best_model = models[0]\n",
        "\n",
        "best_model.build(input_shape=(None, 256))\n",
        "best_model.summary()\n",
        "\n",
        "tuner.get_best_hyperparameters()[0].values\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.001,\n",
        "    beta_1=0.9,\n",
        "    beta_2 = 0.999,\n",
        "    epsilon=1e-08,\n",
        "    amsgrad=False,\n",
        "    name=\"Adam\",\n",
        ")\n",
        "\n",
        "best_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=metrics)\n",
        "best_model.summary()\n",
        "\n",
        "callbacks = [tf.keras.callbacks.EarlyStopping(\n",
        "    monitor = 'val_loss', min_delta = 0, patience = 10, verbose = 0,\n",
        "    mode = 'auto', baseline = None, restore_best_weights = True\n",
        ")]\n",
        "\n",
        "history = best_model.fit(train_ds, epochs=100, validation_data=eval_ds, steps_per_epoch=steps_per_epoch, callbacks=callbacks)\n",
        "\n",
        "model_name = 'tamu_hypertuned'\n",
        "model_path = f'models/nsfw_Keras_with_CLIP_{model_name}'\n",
        "tf.keras.models.save_model(best_model, model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBUyujcSARnU"
      },
      "outputs": [],
      "source": [
        "def copy_local_directory_to_gcs(local_path, bucket, gcs_path):\n",
        "    \"\"\"Recursively copy a directory of files to GCS.\n",
        "    local_path should be a directory and not have a trailing slash.\n",
        "    \"\"\"\n",
        "    assert os.path.isdir(local_path)\n",
        "    for local_file in glob.glob(local_path + '/**'):\n",
        "        if not os.path.isfile(local_file):\n",
        "            dir_name = os.path.basename(os.path.normpath(local_file))\n",
        "            copy_local_directory_to_gcs(local_file, bucket, f\"{gcs_path}/{dir_name}\")\n",
        "        else:\n",
        "            remote_path = os.path.join(gcs_path, local_file[1 + len(local_path) :])\n",
        "            blob = bucket.blob(remote_path)\n",
        "            blob.upload_from_filename(local_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FzOn1NBARnU"
      },
      "outputs": [],
      "source": [
        "client = storage.Client(project=...)\n",
        "bucket = client.get_bucket(...)\n",
        "copy_local_directory_to_gcs(model_path, bucket, model_path)\n",
        "copy_local_directory_to_gcs('tuner_dir', bucket, 'tuner_dir')\n",
        "loaded_model = tf.keras.models.load_model(model_path)\n",
        "print(history.history.keys())\n",
        "\n",
        "plt.figure(figsize = (20, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(history.history['auc'])\n",
        "plt.plot(history.history['val_auc'])\n",
        "plt.title('model auc')\n",
        "plt.ylabel('auc')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(history.history['precision_at_recall'])\n",
        "plt.plot(history.history['val_precision_at_recall'])\n",
        "plt.title('model precision at 0.9 recall')\n",
        "plt.ylabel('precision_at_recall')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "\n",
        "plt.savefig('history_with_twitter_clip.pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWvZ3nGAARnU"
      },
      "outputs": [],
      "source": [
        "test_labels = []\n",
        "test_preds = []\n",
        "\n",
        "for batch_features, batch_labels in tqdm(test_ds):\n",
        "    test_preds.extend(loaded_model.predict_proba(batch_features))\n",
        "    test_labels.extend(batch_labels.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5e3QepwZARnV"
      },
      "outputs": [],
      "source": [
        "test_sens_prev_labels = []\n",
        "test_sens_prev_preds = []\n",
        "\n",
        "for batch_features, batch_labels in tqdm(test_sens_prev_ds):\n",
        "    test_sens_prev_preds.extend(loaded_model.predict_proba(batch_features))\n",
        "    test_sens_prev_labels.extend(batch_labels.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkif1Gp4ARnV"
      },
      "outputs": [],
      "source": [
        "n_test_pos = 0\n",
        "n_test_neg = 0\n",
        "n_test = 0\n",
        "\n",
        "for label in test_labels:\n",
        "    n_test +=1\n",
        "    if label == 1:\n",
        "        n_test_pos += 1\n",
        "    else:\n",
        "        n_test_neg += 1\n",
        "\n",
        "print(f'n_test = {n_test}, n_pos = {n_test_pos}, n_neg = {n_test_neg}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLiedW7KARnV"
      },
      "outputs": [],
      "source": [
        "n_test_sens_prev_pos = 0\n",
        "n_test_sens_prev_neg = 0\n",
        "n_test_sens_prev = 0\n",
        "\n",
        "for label in test_sens_prev_labels:\n",
        "    n_test_sens_prev += 1\n",
        "    if label == 1:\n",
        "        n_test_sens_prev_pos += 1\n",
        "    else:\n",
        "        n_test_sens_prev_neg += 1\n",
        "\n",
        "print(f'n_test_sens_prev = {n_test_sens_prev}, n_pos_sens_prev = {n_test_sens_prev_pos}, n_neg = {n_test_sens_prev_neg}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEHc6MDbARnV"
      },
      "outputs": [],
      "source": [
        "test_weights = np.ones(np.asarray(test_preds).shape)\n",
        "\n",
        "test_labels = np.asarray(test_labels)\n",
        "test_preds = np.asarray(test_preds)\n",
        "test_weights = np.asarray(test_weights)\n",
        "\n",
        "pr = sklearn.metrics.precision_recall_curve(\n",
        "    test_labels,\n",
        "    test_preds\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkZzdHDCARnV"
      },
      "outputs": [],
      "source": [
        "auc = sklearn.metrics.auc(pr[1], pr[0])\n",
        "plt.plot(pr[1], pr[0])\n",
        "plt.title(\"nsfw (MU test set)\")\n",
        "\n",
        "test_sens_prev_weights = np.ones(np.asarray(test_sens_prev_preds).shape)\n",
        "\n",
        "test_sens_prev_labels = np.asarray(test_sens_prev_labels)\n",
        "test_sens_prev_preds = np.asarray(test_sens_prev_preds)\n",
        "test_sens_prev_weights = np.asarray(test_sens_prev_weights)\n",
        "\n",
        "pr_sens_prev = sklearn.metrics.precision_recall_curve(\n",
        "    test_sens_prev_labels,\n",
        "    test_sens_prev_preds\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_nJrSV1ARnV"
      },
      "outputs": [],
      "source": [
        "auc_sens_prev = sklearn.metrics.auc(pr_sens_prev[1], pr_sens_prev[0])\n",
        "plt.plot(pr_sens_prev[1], pr_sens_prev[0])\n",
        "plt.title(\"nsfw (sens prev test set)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQbwWwWEARnW"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(\n",
        "    {\n",
        "        \"label\": test_labels.squeeze(),\n",
        "        \"preds_keras\": np.asarray(test_preds).flatten()\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GH1oMrnLARnW"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 10))\n",
        "df[\"preds_keras\"].hist()\n",
        "plt.title(\"Keras predictions\", size=20)\n",
        "plt.xlabel('score')\n",
        "plt.ylabel(\"freq\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4I3mTE0ARnW"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (20, 5))\n",
        "plt.subplot(1, 3, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4ZNtUbuARnW"
      },
      "outputs": [],
      "source": [
        "plt.plot(pr[2], pr[0][0:-1])\n",
        "plt.xlabel(\"threshold\")\n",
        "plt.ylabel(\"precision\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6JAEeY5ARnW"
      },
      "outputs": [],
      "source": [
        "plt.subplot(1, 3, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NC5jw90YARnX"
      },
      "outputs": [],
      "source": [
        "plt.plot(pr[2], pr[1][0:-1])\n",
        "plt.xlabel(\"threshold\")\n",
        "plt.ylabel(\"recall\")\n",
        "plt.title(\"Keras\", size=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ftkrr3YtARnX"
      },
      "outputs": [],
      "source": [
        "plt.subplot(1, 3, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDrGI9OuARnX"
      },
      "outputs": [],
      "source": [
        "plt.plot(pr[1], pr[0])\n",
        "plt.xlabel(\"recall\")\n",
        "plt.ylabel(\"precision\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWYoL1niARnb"
      },
      "outputs": [],
      "source": [
        "plt.savefig('with_tamu_clip.pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpZKmbmCARnc"
      },
      "outputs": [],
      "source": [
        "def get_point_for_recall(recall_value, recall, precision):\n",
        "    idx = np.argmin(np.abs(recall - recall_value))\n",
        "\n",
        "    return (recall[idx], precision[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TgLRhe6ARnc"
      },
      "outputs": [],
      "source": [
        "def get_point_for_precision(precision_value, recall, precision):\n",
        "    idx = np.argmin(np.abs(precision - precision_value))\n",
        "\n",
        "    return (recall[idx], precision[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Z8gkY3KARnc"
      },
      "outputs": [],
      "source": [
        "precision, recall, thresholds = pr\n",
        "\n",
        "auc_precision_recall = sklearn.metrics.auc(recall, precision)\n",
        "\n",
        "print(auc_precision_recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omTyVzIEARnc"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 10))\n",
        "plt.plot(recall, precision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0pCnTMyARnc"
      },
      "outputs": [],
      "source": [
        "plt.xlabel(\"recall\")\n",
        "plt.ylabel(\"precision\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pshoCCDARnc"
      },
      "outputs": [],
      "source": [
        "ptAt50 = get_point_for_recall(0.5, recall, precision)\n",
        "print(ptAt50)\n",
        "plt.plot( [ptAt50[0],ptAt50[0]], [0,ptAt50[1]], 'r')\n",
        "plt.plot([0, ptAt50[0]], [ptAt50[1], ptAt50[1]], 'r')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U61VzlxIARnd"
      },
      "outputs": [],
      "source": [
        "ptAt90 = get_point_for_recall(0.9, recall, precision)\n",
        "print(ptAt90)\n",
        "plt.plot( [ptAt90[0],ptAt90[0]], [0,ptAt90[1]], 'b')\n",
        "plt.plot([0, ptAt90[0]], [ptAt90[1], ptAt90[1]], 'b')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xIyet3wARnd"
      },
      "outputs": [],
      "source": [
        "ptAt50fmt = \"%.4f\" % ptAt50[1]\n",
        "ptAt90fmt = \"%.4f\" % ptAt90[1]\n",
        "aucFmt = \"%.4f\" % auc_precision_recall\n",
        "plt.title(\n",
        "    f\"Keras (nsfw MU test)\\nAUC={aucFmt}\\np={ptAt50fmt} @ r=0.5\\np={ptAt90fmt} @ r=0.9\\nN_train={...}} ({...} pos), N_test={n_test} ({n_test_pos} pos)\", size = 20\n",
        ")\n",
        "plt.subplots_adjust(top=0.72)\n",
        "plt.savefig('recall_precision_nsfw_Keras_with_twitter_CLIP_MU_test.pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ptDvx_kARnd"
      },
      "outputs": [],
      "source": [
        "precision, recall, thresholds = pr_sens_prev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DdXiwGiARnd"
      },
      "outputs": [],
      "source": [
        "auc_precision_recall = sklearn.metrics.auc(recall, precision)\n",
        "print(auc_precision_recall)\n",
        "plt.figure(figsize=(15, 10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAA8-u4oARnd"
      },
      "outputs": [],
      "source": [
        "plt.plot(recall, precision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9wukT1QARnd"
      },
      "outputs": [],
      "source": [
        "plt.xlabel(\"recall\")\n",
        "plt.ylabel(\"precision\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2nIBiS4ARne"
      },
      "outputs": [],
      "source": [
        "ptAt50 = get_point_for_recall(0.5, recall, precision)\n",
        "print(ptAt50)\n",
        "plt.plot( [ptAt50[0],ptAt50[0]], [0,ptAt50[1]], 'r')\n",
        "plt.plot([0, ptAt50[0]], [ptAt50[1], ptAt50[1]], 'r')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZfVJVAnARne"
      },
      "outputs": [],
      "source": [
        "ptAt90 = get_point_for_recall(0.9, recall, precision)\n",
        "print(ptAt90)\n",
        "plt.plot( [ptAt90[0],ptAt90[0]], [0,ptAt90[1]], 'b')\n",
        "plt.plot([0, ptAt90[0]], [ptAt90[1], ptAt90[1]], 'b')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gmio64onARne"
      },
      "outputs": [],
      "source": [
        "ptAt50fmt = \"%.4f\" % ptAt50[1]\n",
        "ptAt90fmt = \"%.4f\" % ptAt90[1]\n",
        "aucFmt = \"%.4f\" % auc_precision_recall\n",
        "plt.title(\n",
        "    f\"Keras (nsfw sens prev test)\\nAUC={aucFmt}\\np={ptAt50fmt} @ r=0.5\\np={ptAt90fmt} @ r=0.9\\nN_train={...} ({...} pos), N_test={n_test_sens_prev} ({n_test_sens_prev_pos} pos)\", size = 20\n",
        ")\n",
        "plt.subplots_adjust(top=0.72)\n",
        "plt.savefig('recall_precision_nsfw_Keras_with_tamu_CLIP_sens_prev_test.pdf')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}